[["index.html", "STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 1", " STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 1 In week 1, we have studied how to use principal component analysis (PCA) to perform dimension reduction. Before implementing PCA, we should always check that the variables are continuous and perform some exploratory analysis. Some useful codes include: str, skim, summary, cor #for numerical summaries plot, pairs #for graphical summaries Next, we perform PCA by using the command princomp. If the variables have been recorded on different scales or they have very different variances, then it is advisable to base the analysis on the sample correlation matrix; in this case, we set the second argument cor to TRUE. Otherwise, covariance matrix is preferred (no need to include the second argument). my.pca &lt;- princomp(my.data, cor=TRUE) #correlation-based PCA my.pca &lt;- princomp(my.data) #covariance-based PCA To determine the number of principal components to be retained, we could use Proportion of Variation, Kaiser's method and Cattell's method. The former two methods require the standard deviation of each principal component, which can be found by using summary(my.pca) or my.pca$sdev. The last method requires a scree plot, which can be produced by using plot(my.pca). Finally, once PCA is performed, we can interpret the principal components by looking at the loadings (my.pca$loadings). Observations in the new PC coordinate system, i.e. scores, are stored in my.pca$scores. A new observation can be projected into the PC space by using predict(my.pca, new.data). "],["exercise-1-tasks-in-lecture-notes.html", "2 Exercise 1: Tasks in lecture notes", " 2 Exercise 1: Tasks in lecture notes In the lecture note, we looked at the wines dataset and explained how to apply PCA to it. You may re-run the following codes to import the data and perform PCA. wine &lt;- read.csv(&quot;wine.data.csv&quot;) wine.new&lt;-wine[-122,-1] wine.pca&lt;-princomp(wine.new, cor=T) summary(wine.pca) ## Importance of components: ## Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 ## Standard deviation 2.1861 1.5899 1.1601 0.96171 0.92826 0.80043 0.74398 ## Proportion of Variance 0.3676 0.1945 0.1035 0.07114 0.06628 0.04928 0.04258 ## Cumulative Proportion 0.3676 0.5621 0.6656 0.73675 0.80303 0.85232 0.89489 ## Comp.8 Comp.9 Comp.10 Comp.11 Comp.12 Comp.13 ## Standard deviation 0.57942 0.53979 0.50244 0.48134 0.40738 0.29864 ## Proportion of Variance 0.02583 0.02241 0.01942 0.01782 0.01277 0.00686 ## Cumulative Proportion 0.92072 0.94313 0.96255 0.98037 0.99314 1.00000 Task 2 (in the lecture note) How many components should we have chosen if we wanted 80% of the original variability explained? Answer: components What about 95%? Answer: components Hint Look at the row \"Cumulative Proportion\" and find the column whose value is larger than the required proportion of variance explained. Task 3 Some social scientists use Joliffeâ€™s rule, which says that for a PCA run on correlation, only those PCs with variation above 0.6 should be retained. How many PCs should be retained according to this rule? Answer: components Hint Use wine.pca$sdev to find the standard deviation and thus the variance of each PC. Task 4 Looking at the loadings of the PCA, how would you interpret the third principal component? Task 5 Calculate the first component score for the new observation \\((12,4,3,25,100,2,1,0.4,2,4,1,2,600)\\) by hand (using R as a calculator) Answer: The first component score for the new observation is . Hint Step 1. princomp automatically mean-centres each variable. Therefore, you will have to centre the new observation by taking away the centre vector; the centring vector is stored in wine.pca$center. Step 2. Since we used the correlation matrix and so we were working with standardised data, you will have to scale the resulting centred vector by dividing by the scale vector; the scale vector is stored in wine.pca$scale. Step 3. According to the definition, (PC) scores are the inner product of the new observation (after mean-centring and standardisation) and the first principal component loading vector; the 1st PC loadings are stored in wine.pca$loadings[,1]. Calculate the first component score for the new observation \\((12,4,3,25,100,2,1,0.4,2,4,1,2,600)\\) by using the predict command. Answer: The first component score for the new observation is . "],["exercise-2-employment-in-europe.html", "3 Exercise 2: Employment in Europe", " 3 Exercise 2: Employment in Europe In this example we are going to look at a data set on employment in 26 European countries and perform PCA. The data gives for each of 26 European countries the percentage of the total workforce employed in nine different industries in 1979 (Hand et al, 1994). Variable name Description Agriculture % employed in agriculture Mining % employed in mining Manufacture % employed in manufacturing Power % employed in power supply industries Construction % employed in construction Service % employed in service industries Finance % employed in finance Social % employed in social and personal services Transport % employed in transport &amp; communications employ&lt;-read.table(&quot;eurojob.txt&quot;,header=T,row.names=1);head(employ,4) ## AGRIC MINING MANU POWER CONSTR SERVICE FINANCE SOCIAL TRANS ## Belgium 3.3 0.9 27.6 0.9 8.2 19.1 6.2 26.6 7.2 ## Denmark 9.2 0.1 21.8 0.6 8.3 14.6 6.5 32.2 7.1 ## France 10.8 0.8 27.5 0.9 8.9 16.8 6.0 22.6 5.7 ## WGerm 6.7 1.3 35.8 0.9 7.3 14.4 5.0 22.3 6.1 Task Perform exploratory data analysis (i.e. numerical summaries and some sensible plots) for these data. Comment on the results. Hint For numerical summaries, you could use summary or skim. For plots, you could use pairs. Produce two important numerical summaries for deciding on how to run PCA and to tell how successful it is likely to be. Comment on these. Hint Think about which statistics you will need in order to decide whether PCA might useful for this data, and whether to use covariance-based PCA or correlation-based PCA. Run PCA on the appropriate matrix and look at the output. Hint Use the princomp command to implement PCA. Assuming we are most concerned with preserving information, how many coefficients should we retain if we want to have 90% of the original variability kept? Answer: components Assuming we want to use Cattell's method, how many components would we retain? Hint Use plot on your PCA model to produce a scree plot and look for the bend/elbow. Answer: components Assuming we want to use Kaiser's method, how many components would we retain? Answer: components Assuming we have decided to retain 2 components, is there any useful interpretation to be had for these? Hint Look at the loadings by using $loadings. Produce a scatterplot of the data's scores for the first \\(2\\) PCs and comment. Hint PC scores are stored in$scoresand a scatterplot can be produced by usingplot`. Say we have the following two new observations. obs1&lt;-c(5.1,0.5,32.3,0.8,8.1,16.7,4.3,21.2,6.3) obs2&lt;-c(4.2,0.7,25.4,0.7,9.3,15.0,5.8,31.0,6.9) Calculate their scores on the second principal component. Answer: The second component score for obs1 is and the second component score for obs2 is . Hint You will need to mean-centre and standardise both observations first and then multiply them by the second PC loadings. "],["optional-implementing-pca-using-prcomp.html", "4 Optional: Implementing PCA using prcomp", " 4 Optional: Implementing PCA using prcomp The following code will produce the PCA output given in the tortues videos in the lecture. Try re-running the code using prcomp instead of princomp. (Just start with the data with the outlier removed) #Setting the random generator seed to ensure similar responses when re-running code set.seed(135) ################################## #Reading in and preparing the data ################################## #Open the library ade4 where the data is library(ade4) #Load the tortues dataset data(&quot;tortues&quot;) #Look at the first few lines of the data head(tortues) #Extract the females turtles data into a new dataset called fem.turt fem.turt&lt;-tortues[tortues[,4]==&quot;F&quot;,-4] #Take the log of all the variables in the new dataset log.fem.turt&lt;-log(fem.turt) #Name the variables colnames(log.fem.turt)&lt;-c(&quot;log.length&quot;,&quot;log.width&quot;, &quot;log.breadth&quot;) ############## #Summary Plots ############## #Create a pairsplot of the data pairs(log.fem.turt,pch=20, lower.panel=NULL) #Create a 3-d scatterplot of the data library(lattice) cloud(log.length~log.width*log.breadth,data=log.fem.turt) #Rotate the 3-d scatterplot of the data library(TeachingDemos) #Use your mouse to drag the sliders to change the plot rotate.cloud(log.length~log.width*log.breadth,data=log.fem.turt) #################### #Numerical Summaries #################### #Correlation matrix round(cor(log.fem.turt),2) #Standard deviations apply(log.fem.turt,2,sd) ############################# #Principal Component Analysis ############################# pca.turt&lt;-princomp(log.fem.turt);pca.turt #Change princomp to prcomp and use the help page to find out loadings, scores etc. ###################### #Looking at the scores ###################### head(pca.turt$scores);plot(pca.turt$scores,pch=20) #outlier&lt;-identify(pca.turt$scores) ##################################### #Run PCA on dataset excluding outlier ##################################### pca.turt.new&lt;-princomp(log.fem.turt[-10,]);pca.turt.new #################################### #Deciding on number of PCs to retain #################################### plot(pca.turt.new);summary(pca.turt.new) sd.pca&lt;-summary(pca.turt.new)$sdev tot.var&lt;-sum(sd.pca^2) ave.var&lt;-tot.var/ncol(log.fem.turt) ave.var sd.pca^2&gt;ave.var ########################## #Interpreting the loadings ########################## pca.turt.new$loadings ####################### #Calculating new scores ####################### new.data&lt;-data.frame(log.length=c(4.8),log.width=c(4.7),log.breadth=c(3.9)) predict(pca.turt.new,new.data) Hint The princomp() is replaced with prcomp(). The loadings $loadings are replaced with $rotation. The scores $scores are replaced with $x. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
